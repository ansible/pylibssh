---

name: ðŸ— ðŸ“¦ & test & publish

on:  # yamllint disable-line rule:truthy
  create:  # is used for publishing to PyPI and TestPyPI
    tags:  # any tag regardless of its name, no branches
    - >-
      **
    branches-ignore:
    - >-
      **
  push:  # publishes to TestPyPI pushes to the main branch
    branches:  # any branch but not tag
    - >-
      **
    - >-  # NOTE: "branches-ignore" cannot be used with "branches"
      !dependabot/**
    - >-  # NOTE: pre-commit.ci always creats a PR
      !pre-commit-ci-update-config
    tags-ignore:
    - >-
      **
  pull_request:
    paths-ignore:  # NOTE: cannot be combined with "paths"
    - docs/**.rst
  workflow_run:
    workflows:
    - â™² manylinux containers
    branches:
    - devel
    types:
    - completed

concurrency:
  group: >-
    ${{
        github.workflow
    }}-${{
        github.ref_type
    }}-${{
        github.event.pull_request.number || github.sha
    }}
  cancel-in-progress: true

env:
  FORCE_COLOR: 1  # Request colored output from CLI tools supporting it
  MYPY_FORCE_COLOR: 1  # MyPy's color enforcement
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  PIP_NO_PYTHON_VERSION_WARNING: 1
  PIP_NO_WARN_SCRIPT_LOCATION: 1
  PY_COLORS: 1  # Recognized by the `py` package, dependency of `pytest`
  TOX_PARALLEL_NO_SPINNER: 1
  TOX_TESTENV_PASSENV: >-  # Make tox-wrapped tools see color requests
    FORCE_COLOR
    MYPY_FORCE_COLOR
    NO_COLOR
    PY_COLORS
    PYTEST_THEME
    PYTEST_THEME_MODE


jobs:
  pre-setup:
    name: Pre-set global build settings
    if: >-  # https://twitter.com/webKnjaZ/status/1308803017001652225
      github.event_name != 'create' ||
      github.event.ref_type == 'tag'
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: python
    outputs:
      dist-version: ${{ steps.scm-version.outputs.dist-version }}
      is-untagged-devel: >-
        ${{ steps.not-tagged-check.outputs.is-untagged-devel || false }}
      is-tagged: ${{ steps.tagged-check.outputs.is-tagged || false }}
      profiling-enabled: >-
        ${{ steps.profiling-check.outputs.profiling-enabled || false }}
      cache-key-files: >-
        ${{ steps.calc-cache-key-files.outputs.files-hash-key }}
    steps:
    - name: Switch to using Python 3.9 by default
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.9
    - name: >-
        Mark the build as non-tagged
        ${{ github.event.repository.default_branch }} build
      id: not-tagged-check
      if: >-
        github.event_name == 'push' &&
        github.ref == format(
          'refs/heads/{0}', github.event.repository.default_branch
        )
      run: |
        from os import environ
        from pathlib import Path

        FILE_APPEND_MODE = 'a'

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print('is-untagged-devel=true', file=outputs_file)
    - name: Mark the build as tagged
      id: tagged-check
      if: >-  # "create" workflows run separately from "push" & "pull_request"
        github.event_name == 'create' &&
        github.event.ref_type == 'tag'
      run: |
        from os import environ
        from pathlib import Path

        FILE_APPEND_MODE = 'a'

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print('is-tagged=true', file=outputs_file)
    - name: Enable profiling of the build
      id: profiling-check
      if: >-
        steps.tagged-check.outputs.is-tagged != 'true'
      run: |
        from os import environ
        from pathlib import Path

        FILE_APPEND_MODE = 'a'

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print('profiling-enabled=true', file=outputs_file)
    - name: Check out src from Git
      uses: actions/checkout@v3.1.0
      with:
        fetch-depth: >-
          ${{ steps.tagged-check.outputs.is-tagged == 'true' && 1 || 0 }}
    - name: >-
        Calculate Python interpreter version hash value
        for use in the cache key
      id: calc-cache-key-py
      run: |
        from hashlib import sha512
        from os import environ
        from pathlib import Path
        from sys import version

        FILE_APPEND_MODE = 'a'

        hash = sha512(version.encode()).hexdigest()

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(f'py-hash-key={hash}', file=outputs_file)
    - name: >-
        Calculate dependency files' combined hash value
        for use in the cache key
      id: calc-cache-key-files
      run: |
        from hashlib import sha512
        from os import environ
        from pathlib import Path

        FILE_APPEND_MODE = 'a'

        hashes_combo = sha512('-'.join((
          "${{ hashFiles('setup.cfg') }}",
          "${{ hashFiles('tox.ini')}}",
          "${{ hashFiles('pyproject.toml') }}",
          "${{ hashFiles('.pre-commit-config.yaml') }}",
          "${{ hashFiles('pytest.ini') }}",
          "${{ hashFiles('requirements-build.*') }}",
          "${{ hashFiles('docs/requirements.*') }}",
        )).encode()).hexdigest()

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(f"files-hash-key={hashes_combo}", file=outputs_file)
    - name: Set up pip cache
      uses: actions/cache@v3.0.11
      with:
        path: >-
          ${{
              runner.os == 'Linux'
              && '~/.cache/pip'
              || '~/Library/Caches/pip'
          }}
        key: >-
          ${{ runner.os }}-pip-${{
          steps.calc-cache-key-py.outputs.py-hash-key }}-${{
          steps.calc-cache-key-files.outputs.files-hash-key }}
        restore-keys: |
          ${{ runner.os }}-pip-${{
            steps.calc-cache-key-py.outputs.py-hash-key
          }}-
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Drop Git tags from HEAD for non-tag-create events
      if: >-
        steps.tagged-check.outputs.is-tagged != 'true'
      run: >-
        git tag --points-at HEAD
        |
        xargs git tag --delete
      shell: bash
    - name: Set up versioning prerequisites
      run: >-
        python -m
        pip install
        --user
        setuptools-scm
      shell: bash
    - name: Set the current dist version
      id: scm-version
      run: |
        from os import environ
        from pathlib import Path

        import setuptools_scm

        FILE_APPEND_MODE = 'a'

        ver = setuptools_scm.get_version(
          ${{
              steps.untagged-check.outputs.is-untagged-devel == 'true'
              && 'local_scheme="no-local-version"'
              || ''
          }}
        )
        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(f'dist-version={ver}', file=outputs_file)

  build-bin-macos:
    name: ðŸ— macOS ðŸ“¦ for ðŸ ${{ matrix.python-version }}
    needs:
    - pre-setup
    # NOTE: I tried also making wheels for 32-bit runtime but it's
    # NOTE: proven to be useless and hard to maintain. Also macOS
    # NOTE: Catalina ditched support for 32-bit executables so it
    # NOTE: doesn't really make sense to try shimming it.
    runs-on: macos-latest
    strategy:
      matrix:
        python-version:
        # NOTE: Research on the wheel names / platform tags and how they
        # NOTE: are matched under various macOS versions:
        # NOTE: https://github.com/MacPython/wiki/wiki/Spinning-wheels
        - "3.11"
        - "3.10"
        - 3.9
        - 3.8
        - 3.7
        - 3.6

    env:
      ANSIBLE_PYLIBSSH_TRACING: >-
        ${{ fromJSON(needs.pre-setup.outputs.profiling-enabled) && 1 || 0 }}
      PEP517_BUILD_ARGS: --wheel
      TOXENV: build-wheels-pip,delocate-macos-wheels,metadata-validation
      TOX_PARALLEL_NO_SPINNER: 1

    steps:
    - name: Patch env context to match docs expectations
      run: |
        from __future__ import print_function
        import os
        with open(os.environ['GITHUB_ENV'], 'a') as env_file:
            env_file.write(
                'HOME={home_dir}\n'.
                format(home_dir=os.environ['HOME'])
            )
      shell: python
    - uses: actions/checkout@v3.1.0
    - name: Install python ${{ matrix.python-version }}
      uses: actions/setup-python@v4.3.0
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install libssh from brew
      run: brew install libssh  # @0.9.4  # pinning the version does not work
    # FIXME: can we pre-build libssh once in a pre-requisite job?
    # NOTE: Currently we use a brew-installed libssh build that also
    # NOTE: pulls-in openssl@1.1 as well. In the future we may want to
    # NOTE: be in control of what and how we build. This is what the
    # NOTE: commented out code below is for. Doing own builds may help
    # NOTE: us produce a smaller footprint by not building the server-
    # NOTE: side APIs. Controlling the supply chain is also safer from
    # NOTE: the security perspective. Also, it breaks when brew replaces
    # NOTE: the versions.
    # - name: Fetch libssh src
    #   env:
    #     LIBSSH_VERSION: 0.9.3
    #   run: >-
    #     git clone --depth=1
    #     -b "libssh-${{ env.LIBSSH_VERSION }}"
    #     https://git.libssh.org/projects/libssh.git
    # - name: Make libssh build dir
    #   run: mkdir -pv build
    #   working_directory: libssh
    # - name: Build libssh
    #   env:
    #     CFLAGS: -I/usr/local/opt/openssl/include
    #     LDFLAGS: -L/usr/local/opt/openssl/lib
    #   run: |
    #     cmake ..
    #     make
    #     make install/strip
    #   working_directory: libssh/build
    - name: Install tox
      run: python -m pip install --user tox
    - name: >-
        Calculate Python interpreter version hash value
        for use in the cache key
      id: calc-cache-key-py
      run: |
        from hashlib import sha512
        from os import environ
        from pathlib import Path
        from sys import version

        FILE_APPEND_MODE = 'a'

        hash = sha512(version.encode()).hexdigest()

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(f'py-hash-key={hash}', file=outputs_file)
      shell: python
    - name: Set up pip cache
      uses: actions/cache@v3.0.11
      with:
        path: >-
          ${{
              runner.os == 'Linux'
              && '~/.cache/pip'
              || '~/Library/Caches/pip'
          }}
        key: >-
          ${{ runner.os }}-pip-${{
          steps.calc-cache-key-py.outputs.py-hash-key }}-${{
          needs.pre-setup.outputs.cache-key-files }}
        restore-keys: |
          ${{ runner.os }}-pip-${{
            steps.calc-cache-key-py.outputs.py-hash-key
          }}-
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Check out src from Git
      uses: actions/checkout@v3.1.0
      with:
        fetch-depth: >-
          ${{ fromJSON(needs.pre-setup.outputs.is-tagged) && 1 || 0 }}
    - name: Drop Git tags from HEAD for non-tag-create events
      if: >-
        !fromJSON(needs.pre-setup.outputs.is-tagged)
      run: >-
        git tag --points-at HEAD
        |
        xargs git tag --delete
      shell: bash
    - name: Pre-populate tox env
      run: python -m tox -p auto --parallel-live -vvvv --notest
    - name: Install toml Python distribution package
      if: fromJSON(needs.pre-setup.outputs.is-untagged-devel)
      run: >-
        python -m pip install --user toml
    - name: Instruct setuptools-scm not to add a local version part
      if: fromJSON(needs.pre-setup.outputs.is-untagged-devel)
      run: |
        import toml
        with open('pyproject.toml') as pyproject_toml:
            pyproj = toml.load(pyproject_toml)

        pyproj['tool']['setuptools_scm']['local_scheme'] = 'no-local-version'
        with open('pyproject.toml', 'w') as pyproject_toml:
            toml.dump(pyproj, pyproject_toml)
      shell: python
    - name: Pretend that pyproject.toml is unchanged
      if: fromJSON(needs.pre-setup.outputs.is-untagged-devel)
      run: |
        git diff --color=always
        git update-index --assume-unchanged pyproject.toml
    - name: Build dist
      run: python -m tox -p auto --parallel-live -vvvv -e build-wheels-pip
    - name: Bundle external shared libs
      run: >-
        python -m
        tox
        -p auto
        --parallel-live -vvvv
        -e delocate-macos-wheels
        --
        dist/*.whl
    - name: Verify wheel metadata
      run: python -m tox -p auto --parallel-live -vvvv -e metadata-validation
    - name: Install pytest and its plugins
      run: >-
        python -m
        pip install
        --user
        pytest pytest-cov pytest-xdist pytest-forked
    - name: Install the generated Python wheel distribution
      run: >-
        python -m
        pip install
        --user --no-index
        -f dist
        --only-binary ansible-pylibssh
        ansible-pylibssh
    - name: Run tests using pytest
      run: python -m pytest -m smoke --no-cov
    - name: Store the binary wheel
      uses: actions/upload-artifact@v3
      with:
        name: python-package-distributions
        path: dist
        retention-days: 4

  build-bin-manylinux:
    name: >-
      ðŸ— manylinux${{ matrix.manylinux-year-target
      }}-${{ matrix.manylinux-image-target.arch
      }} ðŸ“¦ for ðŸ ${{ matrix.manylinux-python-target }}
    needs:
    - pre-setup
    runs-on: ubuntu-latest
    strategy:
      matrix:
        manylinux-python-target:
        # NOTE: Must be from this list:
        # NOTE: $ podman run -it --rm \
        # NOTE:   quay.io/pypa/manylinux2014_x86_64 \
        # NOTE:   ls -1 /opt/python
        - cp36-cp36m
        - cp37-cp37m
        - cp38-cp38
        - cp39-cp39
        - cp310-cp310
        - cp311-cp311
        manylinux-year-target:
        - 2014
        - _2_24
        manylinux-image-target:
        # NOTE: Keep in sync with `build-manylinux-container-images.yml`.
        # NOTE: Ordered from "heavy" to "fast".
        - arch: aarch64
          qemu_arch: arm64
        - arch: s390x
        - arch: ppc64le
        - arch: x86_64
          qemu_arch: amd64
        include:
        # NOTE: manylinux2010 only on x86_64
        - manylinux-python-target: cp36-cp36m
          manylinux-image-target:
            arch: x86_64
            qemu_arch: amd64
          manylinux-year-target: 2010
        - manylinux-python-target: cp37-cp37m
          manylinux-image-target:
            arch: x86_64
            qemu_arch: amd64
          manylinux-year-target: 2010
        - manylinux-python-target: cp38-cp38
          manylinux-image-target:
            arch: x86_64
            qemu_arch: amd64
          manylinux-year-target: 2010
        - manylinux-python-target: cp39-cp39
          manylinux-image-target:
            arch: x86_64
            qemu_arch: amd64
          manylinux-year-target: 2010
        - manylinux-python-target: cp310-cp310
          manylinux-image-target:
            arch: x86_64
            qemu_arch: amd64
          manylinux-year-target: 2010
        # NOTE: manylinux1 caps out at Python 3.9
        - manylinux-python-target: cp36-cp36m
          manylinux-image-target:
            arch: x86_64
            qemu_arch: amd64
          manylinux-year-target: 1
        - manylinux-python-target: cp37-cp37m
          manylinux-image-target:
            arch: x86_64
            qemu_arch: amd64
          manylinux-year-target: 1
        - manylinux-python-target: cp38-cp38
          manylinux-image-target:
            arch: x86_64
            qemu_arch: amd64
          manylinux-year-target: 1
        - manylinux-python-target: cp39-cp39
          manylinux-image-target:
            arch: x86_64
            qemu_arch: amd64
          manylinux-year-target: 1

    env:
      ANSIBLE_PYLIBSSH_TRACING: >-
        ${{ fromJSON(needs.pre-setup.outputs.profiling-enabled) && 1 || 0 }}
      DOCKER_EXECUTABLE: podman
      QEMU_ARCH: >-
        ${{
          matrix.manylinux-image-target.qemu_arch
          || matrix.manylinux-image-target.arch
        }}
      TOXENV: >-
        build-dists-manylinux${{ matrix.manylinux-year-target
        }}-${{ matrix.manylinux-image-target.arch }},metadata-validation
      TOX_PARALLEL_NO_SPINNER: 1

    steps:
    - name: Switch to using Python 3.9 by default
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.9
    - name: >-
        Calculate Python interpreter version hash value
        for use in the cache key
      id: calc-cache-key-py
      run: |
        from hashlib import sha512
        from os import environ
        from pathlib import Path
        from sys import version

        FILE_APPEND_MODE = 'a'

        hash = sha512(version.encode()).hexdigest()

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(f'py-hash-key={hash}', file=outputs_file)
      shell: python
    - name: Set up pip cache
      uses: actions/cache@v3.0.11
      with:
        path: >-
          ${{
              runner.os == 'Linux'
              && '~/.cache/pip'
              || '~/Library/Caches/pip'
          }}
        key: >-
          ${{ runner.os }}-pip-${{
          steps.calc-cache-key-py.outputs.py-hash-key }}-${{
          needs.pre-setup.outputs.cache-key-files }}
        restore-keys: |
          ${{ runner.os }}-pip-${{
            steps.calc-cache-key-py.outputs.py-hash-key
          }}-
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install tox
      run: >-
        python -m
        pip install
        --user
        tox
    - name: Check out src from Git
      uses: actions/checkout@v3.1.0
      with:
        fetch-depth: >-
          ${{ fromJSON(needs.pre-setup.outputs.is-tagged) && 1 || 0 }}
    - name: Drop Git tags from HEAD for non-tag-create events
      if: >-
        !fromJSON(needs.pre-setup.outputs.is-tagged)
      run: >-
        git tag --points-at HEAD
        |
        xargs git tag --delete
      shell: bash
    - name: Pre-populate tox env
      run: python -m tox -p auto --parallel-live -vvvv --notest
    - name: Install toml Python distribution package
      if: fromJSON(needs.pre-setup.outputs.is-untagged-devel)
      run: >-
        python -m
        pip install
        --user
        toml
    - name: Instruct setuptools-scm not to add a local version part
      if: fromJSON(needs.pre-setup.outputs.is-untagged-devel)
      run: |
        import toml
        with open('pyproject.toml') as pyproject_toml:
            pyproj = toml.load(pyproject_toml)

        pyproj['tool']['setuptools_scm']['local_scheme'] = 'no-local-version'
        with open('pyproject.toml', 'w') as pyproject_toml:
            toml.dump(pyproj, pyproject_toml)
      shell: python
    - name: Pretend that pyproject.toml is unchanged
      if: fromJSON(needs.pre-setup.outputs.is-untagged-devel)
      run: |
        git diff --color=always
        git update-index --assume-unchanged pyproject.toml
    - name: >-
        Set up QEMU ${{ env.QEMU_ARCH }} arch emulation
        with Podman
      if: env.QEMU_ARCH != 'amd64'
      run: >-
        sudo podman run
        --rm --privileged
        multiarch/qemu-user-static
        --reset -p yes
    - name: >-
        Build ${{ matrix.manylinux-python-target }} dist
        and verify wheel metadata
      run: >-
        python -m
        tox -p auto --parallel-live -vvvv
        --
        ${{ matrix.manylinux-python-target }}
    - name: Store ${{ matrix.manylinux-python-target }} binary wheel
      uses: actions/upload-artifact@v3
      with:
        name: python-package-distributions
        path: dist
        retention-days: 4

  build-src:
    name: ðŸ— an sdist ðŸ“¦
    needs:
    - pre-setup
    runs-on: ubuntu-latest

    env:
      ANSIBLE_PYLIBSSH_TRACING: >-
        ${{ fromJSON(needs.pre-setup.outputs.profiling-enabled) && 1 || 0 }}
      PEP517_BUILD_ARGS: --sdist
      TOXENV: build-dists,metadata-validation
      TOX_PARALLEL_NO_SPINNER: 1

    steps:
    - name: Switch to using Python 3.11 by default
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.11
    - name: >-
        Calculate Python interpreter version hash value
        for use in the cache key
      id: calc-cache-key-py
      run: |
        from hashlib import sha512
        from os import environ
        from pathlib import Path
        from sys import version

        FILE_APPEND_MODE = 'a'

        hash = sha512(version.encode()).hexdigest()

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(f'py-hash-key={hash}', file=outputs_file)
      shell: python
    - name: Set up pip cache
      uses: actions/cache@v3.0.11
      with:
        path: >-
          ${{
              runner.os == 'Linux'
              && '~/.cache/pip'
              || '~/Library/Caches/pip'
          }}
        key: >-
          ${{ runner.os }}-pip-${{
          steps.calc-cache-key-py.outputs.py-hash-key }}-${{
          needs.pre-setup.outputs.cache-key-files }}
        restore-keys: |
          ${{ runner.os }}-pip-${{
            steps.calc-cache-key-py.outputs.py-hash-key
          }}-
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install tox
      run: >-
        python -m
        pip install
        --user
        tox
    - name: Check out src from Git
      uses: actions/checkout@v3.1.0
      with:
        fetch-depth: >-
          ${{ fromJSON(needs.pre-setup.outputs.is-tagged) && 1 || 0 }}
    - name: Drop Git tags from HEAD for non-tag-create events
      if: >-
        !fromJSON(needs.pre-setup.outputs.is-tagged)
      run: >-
        git tag --points-at HEAD
        |
        xargs git tag --delete
      shell: bash
    - name: Pre-populate tox env
      run: python -m tox -p auto --parallel-live -vvvv --notest
    - name: Install toml Python distribution package
      if: fromJSON(needs.pre-setup.outputs.is-untagged-devel)
      run: >-
        python -m
        pip install
        --user
        toml
    - name: Instruct setuptools-scm not to add a local version part
      if: fromJSON(needs.pre-setup.outputs.is-untagged-devel)
      run: |
        import toml
        with open('pyproject.toml') as pyproject_toml:
            pyproj = toml.load(pyproject_toml)

        pyproj['tool']['setuptools_scm']['local_scheme'] = 'no-local-version'
        with open('pyproject.toml', 'w') as pyproject_toml:
            toml.dump(pyproj, pyproject_toml)
      shell: python
    - name: Pretend that pyproject.toml is unchanged
      if: fromJSON(needs.pre-setup.outputs.is-untagged-devel)
      run: |
        git diff --color=always
        git update-index --assume-unchanged pyproject.toml
    - name: Build sdist and verify metadata
      run: python -m tox -p auto --parallel-live -vvvv
    - name: Store the source distribution
      uses: actions/upload-artifact@v3
      with:
        name: python-package-distributions
        path: dist
        retention-days: 4

  build-rpms:
    name: ${{ matrix.target-container.tag }}
    needs:
    - build-src
    - pre-setup  # transitive, for accessing settings
    strategy:
      matrix:
        target-container:
        - tag: fedora:35
        - tag: fedora:36
        - tag: fedora:37
        - tag: centos/centos:stream8
          registry: quay.io
        - tag: ubi8/ubi:8.3
          registry: registry.access.redhat.com
        - tag: ubi8/ubi:8.4
          registry: registry.access.redhat.com
        - tag: ubi8/ubi:8.5
          registry: registry.access.redhat.com
        - tag: ubi8/ubi:8.6
          registry: registry.access.redhat.com
        - tag: ubi9/ubi:9.0.0
          registry: registry.access.redhat.com

    runs-on: ubuntu-latest
    container:
      # NOTE: GHA has poor support for concat which is why I resorted to
      # NOTE: using this ugly ternary syntax
      image: >-
        ${{
          matrix.target-container.registry
          && matrix.target-container.registry
          || ''
        }}${{
          matrix.target-container.registry
          && '/'
          || ''
        }}${{
          matrix.target-container.tag
        }}

    continue-on-error: >-
      ${{
        contains(matrix.target-container.tag, 'ubi9')
        && true
        || false
      }}

    steps:
    - name: Produce artifact name
      id: distribution-meta
      run: |
        dist_tag=$(rpm --eval '%{?dist}')
        echo "dist-tag=${dist_tag}" >> "${GITHUB_OUTPUT}"

    - name: Enable EPEL repository
      if: contains(matrix.target-container.tag, 'centos')
      run: dnf install --assumeyes epel-release

    - name: Install build tooling
      run: >-
        dnf install
        --assumeyes
        dnf-plugins-core
        rpm-build
        ${{
            !contains(matrix.target-container.tag, 'ubi')
            && 'rpmdevtools rpmlint'
            || ''
        }}

    - name: Create rpmbuild directory structure on a community distro
      if: >-
        !contains(matrix.target-container.tag, 'ubi')
      run: rpmdev-setuptree
    - name: Create rpmbuild directory structure on RHEL
      if: contains(matrix.target-container.tag, 'ubi')
      run: mkdir -pv ~/rpmbuild/{BUILD,RPMS,SOURCES,SPECS,SRPMS}

    - name: Grab the source from Git
      uses: actions/checkout@v3.1.0

    - name: Set an SCM version in the spec
      run: >-
        sed -i
        "s#^\(Version:\s\+\).*#\1${{ needs.pre-setup.outputs.dist-version }}#"
        packaging/rpm/ansible-pylibssh.spec

    - name: Download all the dists  # because `rpmlint` executes the spec file
      uses: actions/download-artifact@v3
      with:
        name: python-package-distributions
        path: dist/

    - name: Lint the RPM spec file
      if: >-
        !contains(matrix.target-container.tag, 'ubi')
      run: rpmlint packaging/rpm/ansible-pylibssh.spec

    - name: Copy sdist to the sources dir
      run: >-
        cp -v
        dist/ansible-pylibssh-${{ needs.pre-setup.outputs.dist-version }}.tar.gz
        ~/rpmbuild/SOURCES/

    - name: Install static test dependencies missing from UBI9
      if: contains(matrix.target-container.tag, 'ubi9')
      run: >-
        rpm
        -ivh
        --nodeps
        https://rpmfind.net/linux/centos-stream/"$(
          rpm --eval '%{rhel}'
        )"-stream/CRB/x86_64/os/Packages/python3-pytest-6.2.2-6${{
          steps.distribution-meta.outputs.dist-tag
        }}.noarch.rpm
        https://rpmfind.net/linux/centos-stream/"$(
          rpm --eval '%{rhel}'
        )"-stream/CRB/x86_64/os/Packages/python3-wheel-0.36.2-7${{
          steps.distribution-meta.outputs.dist-tag
        }}.noarch.rpm

    - name: Install static test dependencies missing from UBI8
      if: contains(matrix.target-container.tag, 'ubi8')
      run: >-
        rpm
        -ivh
        --nodeps
        https://vault.centos.org/"$(
          rpm --eval '%{rhel}'
        )".4.2105/BaseOS/x86_64/os/Packages/openssh-8.0p1-6${{
          steps.distribution-meta.outputs.dist-tag
        }}_4.2.x86_64.rpm
        https://rpmfind.net/linux/epel/"$(
          rpm --eval '%{rhel}'
        )"/Everything/x86_64/Packages/p/python3-toml-0.10.0-3${{
          steps.distribution-meta.outputs.dist-tag
        }}.noarch.rpm

    - name: Install static test dependencies missing from all UBIs
      if: contains(matrix.target-container.tag, 'ubi')
      run: >-
        rpm
        -ivh
        --nodeps
        https://rpmfind.net/linux/epel/"$(
          rpm --eval '%{rhel}'
        )"/Everything/x86_64/Packages/p/python3-pytest-cov-${{
          contains(matrix.target-container.tag, 'ubi9')
          && '4.0.0-2'
          || '2.6.0-1'
        }}${{ steps.distribution-meta.outputs.dist-tag }}.noarch.rpm
        https://rpmfind.net/linux/epel/"$(
          rpm --eval '%{rhel}'
        )"/Everything/x86_64/Packages/p/python3-pytest-forked-${{
          contains(matrix.target-container.tag, 'ubi9')
          && '1.4.0'
          || '1.0.2'
        }}-1${{
          steps.distribution-meta.outputs.dist-tag
        }}.noarch.rpm
        https://rpmfind.net/linux/epel/"$(
          rpm --eval '%{rhel}'
        )"/Everything/x86_64/Packages/p/python3-pytest-xdist-${{
          contains(matrix.target-container.tag, 'ubi9')
          && '2.5.0-2'
          || '1.24.1-1'
        }}${{ steps.distribution-meta.outputs.dist-tag }}.noarch.rpm
        https://rpmfind.net/linux/epel/"$(
          rpm --eval '%{rhel}'
        )"/Everything/x86_64/Packages/${{
          contains(matrix.target-container.tag, 'ubi9')
          && 't'
          || 'p'
        }}/${{
          !contains(matrix.target-container.tag, 'ubi9')
          && 'python3-'
          || ''
        }}tox-${{
          contains(matrix.target-container.tag, 'ubi9')
          && '3.26.0-1'
          || '3.4.0-2'
        }}${{ steps.distribution-meta.outputs.dist-tag }}.noarch.rpm
        https://rpmfind.net/linux/epel/"$(
          rpm --eval '%{rhel}'
        )"/Everything/x86_64/Packages/p/python3-execnet-${{
          contains(matrix.target-container.tag, 'ubi9')
          && '1.9.0-3'
          || '1.7.1-1'
        }}${{ steps.distribution-meta.outputs.dist-tag }}.noarch.rpm
        https://rpmfind.net/linux/${{
          contains(matrix.target-container.tag, 'ubi9')
          && 'epel'
          || 'centos'
        }}/"$(
          rpm --eval '%{rhel}'
        )"${{
          !contains(matrix.target-container.tag, 'ubi9')
          && '-stream'
          || ''
        }}/${{
          contains(matrix.target-container.tag, 'ubi9')
          && 'Everything'
          || 'AppStream'
        }}/x86_64/${{
          !contains(matrix.target-container.tag, 'ubi9')
          && 'os/'
          || ''
        }}Packages/${{
          contains(matrix.target-container.tag, 'ubi9')
          && 'p/'
          || ''
        }}python3-coverage-${{
          contains(matrix.target-container.tag, 'ubi9')
          && '6.2-1'
          || '4.5.1-9'
        }}${{ steps.distribution-meta.outputs.dist-tag }}.x86_64.rpm
        https://rpmfind.net/linux/epel/"$(
          rpm --eval '%{rhel}'
        )"/Everything/x86_64/Packages/p/python3-apipkg-${{
          contains(matrix.target-container.tag, 'ubi9')
          && '2.1.1-1'
          || '1.5-6'
        }}${{ steps.distribution-meta.outputs.dist-tag }}.noarch.rpm

    - name: Install static build requirements
      run: dnf builddep --assumeyes --spec packaging/rpm/ansible-pylibssh.spec

    - name: Fetch sources and patches on a community distro
      if: >-
        !contains(matrix.target-container.tag, 'ubi')
      run: >-
        spectool --all --get-files --sourcedir
        packaging/rpm/ansible-pylibssh.spec

    - name: Resolve and install dynamic build deps and build an SRPM on Fedora
      # Ref: https://github.com/rpm-software-management/rpm/commit/58dcfdd
      if: contains(matrix.target-container.tag, 'fedora')
      run: |
        while :
        do
          set +e
          rpmbuild -br packaging/rpm/ansible-pylibssh.spec
          rc="$?"
          [ "${rc}" -eq 0 ] && break
          [ "${rc}" -ne 11 ] && exit "${rc}"
          set -e
          dnf builddep --assumeyes \
            $HOME/rpmbuild/SRPMS/python-ansible-pylibssh-${{
                needs.pre-setup.outputs.dist-version
            }}-1${{
              steps.distribution-meta.outputs.dist-tag
            }}.buildreqs.nosrc.rpm
        done

    - name: Build an SRPM on RHELish
      if: >-
        !contains(matrix.target-container.tag, 'fedora')
      run: >-
        rpmbuild
        ${{
            contains(matrix.target-container.tag, 'ubi')
            && '--undefine=_disable_source_fetch'
            || ''
        }}
        -bs
        packaging/rpm/ansible-pylibssh.spec

    - name: Build binary RPMs
      run: >-
        rpmbuild
        --rebuild
        $HOME/rpmbuild/SRPMS/python-ansible-pylibssh-${{
            needs.pre-setup.outputs.dist-version
        }}-1${{
          steps.distribution-meta.outputs.dist-tag
        }}.src.rpm
    - name: Install the packaged binary RPM on the system
      run: >-
        dnf
        install
        --assumeyes
        $HOME/rpmbuild/RPMS/x86_64/python3-ansible-pylibssh-${{
            needs.pre-setup.outputs.dist-version
        }}-1${{
          steps.distribution-meta.outputs.dist-tag
        }}.x86_64.rpm

    - name: Smoke-test the installed library
      run: >-
        python3 -c
        'from pylibsshext.session import Session; print(Session())'
    - name: Produce artifact name
      id: artifact-name
      run: >-
        normalized_container_id=$(
            echo '${{ matrix.target-container.tag }}' | sed 's#[.\/:]#--#g'
        );
        echo "artifact-id=${normalized_container_id}" >> "${GITHUB_OUTPUT}"
    - name: Store RPM and SRPM as artifacts
      uses: actions/upload-artifact@v3
      with:
        name: ${{ steps.artifact-name.outputs.artifact-id }}--srpm-n-rpm
        path: |
          ~/rpmbuild/SRPMS/
          ~/rpmbuild/RPMS/

  test-matrix:
    name: >-
      Test ðŸ
      ${{ matrix.python-version }}
      ${{ matrix.runner-vm-os }}
      ${{ matrix.dist-type }} dists
    needs:
    - build-bin-macos
    - build-bin-manylinux
    - build-src
    - pre-setup  # transitive, for accessing settings
    runs-on: ${{ matrix.runner-vm-os }}
    strategy:
      matrix:
        python-version:
        - "3.11"
        - "3.10"
        - 3.9
        - 3.8
        - 3.7
        - 3.6
        runner-vm-os:
        - ubuntu-22.04
        - macos-latest
        - ubuntu-20.04
        dist-type:
        - binary
        - source
        exclude:
        - runner-vm-os: ubuntu-22.04
          python-version: 3.6  # EOL, only provided for older OSs

    env:
      ANSIBLE_PYLIBSSH_TRACING: >-
        ${{ fromJSON(needs.pre-setup.outputs.profiling-enabled) && 1 || 0 }}
      TOXENV: test-${{ matrix.dist-type }}-dists
      TOX_PARALLEL_NO_SPINNER: 1

    steps:
    - name: Install build toolchain and openssl headers on Linux
      if: >-
        matrix.dist-type == 'source' &&
        runner.os == 'Linux'
      run: sudo apt update && sudo apt install build-essential libssl-dev
    - name: Install libssh and openssl headers on macOS
      if: >-
        runner.os == 'macOS'
      run: brew install libssh
    - name: Install catchsegv and libssh headers on Linux for cythonize+coverage
      if: >-
        runner.os == 'Linux'
      run: >-
        sudo apt update && sudo apt install ${{
          matrix.runner-vm-os != 'ubuntu-20.04'
          && 'glibc-tools'
          || ''
        }} libssh-dev
    - name: Switch ðŸ to v${{ matrix.python-version }}
      id: python-install
      uses: actions/setup-python@v4.3.0
      with:
        python-version: ${{ matrix.python-version }}
    - name: >-
        Calculate Python interpreter version hash value
        for use in the cache key
      id: calc-cache-key-py
      run: |
        from hashlib import sha512
        from os import environ
        from pathlib import Path
        from sys import version

        FILE_APPEND_MODE = 'a'

        hash = sha512(version.encode()).hexdigest()

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(f'py-hash-key={hash}', file=outputs_file)
      shell: python
    - name: Set up pip cache
      uses: actions/cache@v3.0.11
      with:
        path: >-
          ${{
              runner.os == 'Linux'
              && '~/.cache/pip'
              || '~/Library/Caches/pip'
          }}
        key: >-
          ${{ runner.os }}-pip-${{
          steps.calc-cache-key-py.outputs.py-hash-key }}-${{
          needs.pre-setup.outputs.cache-key-files }}
        restore-keys: |
          ${{ runner.os }}-pip-${{
            steps.calc-cache-key-py.outputs.py-hash-key
          }}-
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install tox
      run: >-
        python -m
        pip install
        --user
        tox
    - name: Check out src from Git
      uses: actions/checkout@v3.1.0
    - name: Download all the dists
      uses: actions/download-artifact@v3
      with:
        name: python-package-distributions
        path: dist/
    - name: Pre-populate tox env
      run: python -m tox -p auto --parallel-live -vvvv --notest
    - name: Configure tox to run pytest under catchsegv
      if: runner.os == 'Linux'
      run: |
        from __future__ import print_function
        import os
        with open(os.environ['GITHUB_ENV'], 'a') as env_file:
            env_file.write('CATCHSEGV_BINARY=catchsegv\n')
      shell: python
    - name: Run tests
      run: python -m tox -p auto --parallel-live -vvvv
    - name: Send coverage data to Codecov
      uses: codecov/codecov-action@v3.1.1
      with:
        files: .test-results/pytest/cov.xml
        flags: >-
          CI-GHA,
          OS-${{
            runner.os
          }},
          VM-${{
            matrix.os
          }},
          Py-${{
            steps.python-install.outputs.python-version
          }}

  dist-meta:
    name: Verify ðŸðŸ“¦ metadata
    needs:
    - build-bin-macos
    - build-bin-manylinux
    - build-src
    - pre-setup  # transitive, for accessing settings
    runs-on: ubuntu-latest

    env:
      TOXENV: metadata-validation
      TOX_PARALLEL_NO_SPINNER: 1

    steps:
    - name: Switch to using Python 3.11 by default
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.11
    - name: >-
        Calculate Python interpreter version hash value
        for use in the cache key
      id: calc-cache-key-py
      run: |
        from hashlib import sha512
        from os import environ
        from pathlib import Path
        from sys import version

        FILE_APPEND_MODE = 'a'

        hash = sha512(version.encode()).hexdigest()

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(f'py-hash-key={hash}', file=outputs_file)
      shell: python
    - name: Set up pip cache
      uses: actions/cache@v3.0.11
      with:
        path: >-
          ${{
              runner.os == 'Linux'
              && '~/.cache/pip'
              || '~/Library/Caches/pip'
          }}
        key: >-
          ${{ runner.os }}-pip-${{
          steps.calc-cache-key-py.outputs.py-hash-key }}-${{
          needs.pre-setup.outputs.cache-key-files }}
        restore-keys: |
          ${{ runner.os }}-pip-${{
            steps.calc-cache-key-py.outputs.py-hash-key
          }}-
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install tox
      run: >-
        python -m
        pip install
        --user
        tox
    - name: Check out src from Git
      uses: actions/checkout@v3.1.0
    - name: Pre-populate tox env
      run: python -m tox -p auto --parallel-live -vvvv --notest
    - name: Download all the dists
      uses: actions/download-artifact@v3
      with:
        name: python-package-distributions
        path: dist/
    - name: Verify metadata
      run: python -m tox -p auto --parallel-live -vvvv

  check:  # This job does nothing and is only used for the branch protection
    if: always()

    needs:
    - build-rpms
    - dist-meta
    - test-matrix

    runs-on: Ubuntu-latest

    steps:
    - name: Decide whether the needed jobs succeeded or failed
      uses: re-actors/alls-green@release/v1
      with:
        jobs: ${{ toJSON(needs) }}

  deploy:
    name: Publish ðŸðŸ“¦ to (Test)PyPI
    needs:
    - check
    - pre-setup  # transitive, for accessing settings
    if: >-
      fromJSON(needs.pre-setup.outputs.is-untagged-devel) ||
      fromJSON(needs.pre-setup.outputs.is-tagged)
    runs-on: ubuntu-latest

    steps:
    - name: Download all the dists
      uses: actions/download-artifact@v3
      with:
        name: python-package-distributions
        path: dist/
    - name: Publish ðŸðŸ“¦ to TestPyPI
      if: >-
        fromJSON(needs.pre-setup.outputs.is-untagged-devel) ||
        fromJSON(needs.pre-setup.outputs.is-tagged)
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        password: ${{ secrets.testpypi_password }}
        repository_url: https://test.pypi.org/legacy/
    - name: Publish ðŸðŸ“¦ to PyPI
      if: fromJSON(needs.pre-setup.outputs.is-tagged)
      uses: pypa/gh-action-pypi-publish@release/v1
      with:
        password: ${{ secrets.pypi_password }}

  dumb-pypi:
    name: Publish nightlies to Dumb PyPI  # https://ansible.github.io/pylibssh/
    needs:
    - check
    - pre-setup  # transitive, for accessing settings
    if: >-
      fromJSON(needs.pre-setup.outputs.is-untagged-devel) ||
      fromJSON(needs.pre-setup.outputs.is-tagged)
    runs-on: ubuntu-latest

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}/simple/ansible-pylibssh/

    permissions:
      contents: read  # This job doesn't need to `git push` anything
      pages: write  # This allows to publish a GitHub Pages site
      # `id-token` allows GitHub Pages to verify the deployment originates
      # from an appropriate source through OpenID Connect, according to the
      # README of the `actions/deploy-pages` action.
      id-token: write

    steps:
    - name: Download the recent published versions from TestPyPI
      run: >-
        python -m
        pip download
        --index-url https://test.pypi.org/simple/
        --dest dist/
        --no-deps
        --pre
        ansible-pylibssh
    - name: Download all the dists
      uses: actions/download-artifact@v3
      with:
        name: python-package-distributions
        path: dist/

    - name: Switch to Python 3.9
      uses: actions/setup-python@v4.3.0
      with:
        python-version: 3.9
    - name: >-
        Calculate Python interpreter version hash value
        for use in the cache key
      id: calc-cache-key-py
      run: |
        from hashlib import sha512
        from os import environ
        from pathlib import Path
        from sys import version

        FILE_APPEND_MODE = 'a'

        hash = sha512(version.encode()).hexdigest()

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(f'py-hash-key={hash}', file=outputs_file)
      shell: python
    - name: Set up pip cache
      uses: actions/cache@v3.0.11
      with:
        path: >-
          ${{
              runner.os == 'Linux'
              && '~/.cache/pip'
              || '~/Library/Caches/pip'
          }}
        key: >-
          ${{ runner.os }}-pip-${{
          steps.calc-cache-key-py.outputs.py-hash-key }}-${{
          needs.pre-setup.outputs.cache-key-files }}
        restore-keys: |
          ${{ runner.os }}-pip-${{
            steps.calc-cache-key-py.outputs.py-hash-key
          }}-
          ${{ runner.os }}-pip-
          ${{ runner.os }}-
    - name: Install dumb-pypi dist from PyPI
      run: python -m pip install dumb-pypi --user
    - name: Generate a dumb PyPI website
      run: |
        python -m dumb_pypi.main \
          --package-list <(ls dist/) \
          --packages-url https://raw.githubusercontent.com/${{
            github.repository
          }}/gh-pages/dist \
          --output-dir gh-pages-dumb-pypi
      shell: bash

    - name: >-
        Copy dists from this build and TestPyPI
        to the generated dumb PyPI website dir
      run: cp -av dist gh-pages-dumb-pypi/

    - name: Upload GitHub Pages artifact
      uses: actions/upload-pages-artifact@v1
      with:
        path: gh-pages-dumb-pypi

    - name: Publish the dumb PyPI website to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v1

...

# TODO: Test install from sdist
#
# TODO: Figure out if we can use Py_LIMITED_API / PEP 384:
# TODO: * https://docs.python.org/3/c-api/stable.html
# TODO: https://github.com/cython/cython/issues/2542
