---

name: â™² ðŸ§ª

on:  # yamllint disable-line rule:truthy
  workflow_call:
    inputs:
      python-version:
        required: true
        type: string
      runner-vm-os:
        required: true
        type: string
      dist-type:
        required: true
        type: string
      yolo:
        required: true
        type: string
      dists-artifact-name:
        description: Workflow artifact name containing dists
        required: true
        type: string
      cython-tracing:
        description: Whether to build Cython modules with line tracing
        default: '0'
        required: false
        type: string
      source-tarball-name:
        description: Sdist filename wildcard
        required: true
        type: string
      cache-key-files:
        description: Dependency files cache
        required: true
        type: string
      release-requested:
        description: Flag whether this is CI run is a release request
        default: 'false'
        required: false
        type: string

env:
  FORCE_COLOR: 1  # Request colored output from CLI tools supporting it
  MYPY_FORCE_COLOR: 1  # MyPy's color enforcement
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  PIP_NO_PYTHON_VERSION_WARNING: 1
  PIP_NO_WARN_SCRIPT_LOCATION: 1
  PY_COLORS: 1  # Recognized by the `py` package, dependency of `pytest`
  TOX_PARALLEL_NO_SPINNER: 1
  TOX_TESTENV_PASSENV: >-  # Make tox-wrapped tools see color requests
    FORCE_COLOR
    MYPY_FORCE_COLOR
    NO_COLOR
    PY_COLORS
    PYTEST_THEME
    PYTEST_THEME_MODE
  TOX_VERSION: tox < 4.12


jobs:
  test-linux:
    name: >-
      ðŸ ${{ inputs.python-version }}@${{ inputs.runner-vm-os }}
      |
      ${{ inputs.dist-type }} dist
    runs-on: ${{ inputs.runner-vm-os }}

    continue-on-error: >-
      ${{
          (
            fromJSON(inputs.release-requested) &&
            !inputs.YOLO
          ) && true || false
      }}

    env:
      ANSIBLE_PYLIBSSH_TRACING: ${{ inputs.cython-tracing }}
      TOXENV: test-${{ inputs.dist-type }}-dists

    steps:
    - name: Install build toolchain and openssl headers on Linux
      if: >-
        inputs.dist-type == 'source' &&
        runner.os == 'Linux'
      run: sudo apt update && sudo apt install build-essential libssl-dev
    - name: Install libssh and openssl headers on macOS
      if: >-
        runner.os == 'macOS'
      run: brew install libssh
    - name: Install catchsegv and libssh headers on Linux for cythonize+coverage
      if: >-
        runner.os == 'Linux'
      run: >-
        sudo apt update && sudo apt install ${{
          inputs.runner-vm-os != 'ubuntu-20.04'
          && 'glibc-tools'
          || ''
        }} libssh-dev
    - name: Switch ðŸ to v${{ inputs.python-version }}
      id: python-install
      uses: actions/setup-python@v5.0.0
      with:
        python-version: ${{ inputs.python-version }}

    - name: Retrieve the project source from an sdist inside the GHA artifact
      uses: re-actors/checkout-python-sdist@release/v1
      with:
        source-tarball-name: ${{ inputs.source-tarball-name }}
        workflow-artifact-name: ${{ inputs.dists-artifact-name }}

    - name: Figure out if the interpreter ABI is stable
      id: py-abi
      run: |
        from os import environ
        from pathlib import Path
        from sys import version_info

        FILE_APPEND_MODE = 'a'

        is_stable_abi = version_info.releaselevel == 'final'

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(
                'is-stable-abi={is_stable_abi}'.
                format(is_stable_abi=str(is_stable_abi).lower()),
                file=outputs_file,
            )
      shell: python
    - name: >-
        Calculate Python interpreter version hash value
        for use in the cache key
      if: fromJSON(steps.py-abi.outputs.is-stable-abi)
      id: calc-cache-key-py
      run: |
        from hashlib import sha512
        from os import environ
        from pathlib import Path
        from sys import version

        FILE_APPEND_MODE = 'a'

        hash = sha512(version.encode()).hexdigest()

        with Path(environ['GITHUB_OUTPUT']).open(
                mode=FILE_APPEND_MODE,
        ) as outputs_file:
            print(f'py-hash-key={hash}', file=outputs_file)
      shell: python
    - name: Set up pip cache
      if: fromJSON(steps.py-abi.outputs.is-stable-abi)
      uses: actions/cache@v4.0.0
      with:
        path: >-
          ${{
              runner.os == 'Linux'
              && '~/.cache/pip'
              || '~/Library/Caches/pip'
          }}
        key: >-
          ${{ runner.os }}-pip-${{
          steps.calc-cache-key-py.outputs.py-hash-key }}-${{
          inputs.cache-key-files }}
        restore-keys: |
          ${{ runner.os }}-pip-${{
            steps.calc-cache-key-py.outputs.py-hash-key
          }}-
          ${{ runner.os }}-pip-
          ${{ runner.os }}-

    - name: Upgrade pip with `requires_python`
      run: >-
        python -m
        pip install
        --user
        --upgrade
        --force-reinstall
        pip-with-requires-python
    - name: Install tox
      run: >-
        python -m
        pip install
        --user
        '${{ env.TOX_VERSION }}'

    - name: Download all the dists
      uses: actions/download-artifact@v3
      with:
        name: ${{ inputs.dists-artifact-name }}
        path: dist/

    - name: >-
        Pre-populate tox env:
        ${{ env.TOXENV }}
      # FIXME: Integrate the following once it's possible
      # --installpkg 'dist/${{ needs.pre-setup.outputs.wheel-artifact-name }}'
      run: >-
        python -m
        tox
        --parallel auto
        --parallel-live
        --skip-missing-interpreters false
        --notest

    - name: Configure tox to run pytest under catchsegv
      if: runner.os == 'Linux'
      run: |
        from __future__ import print_function
        import os
        with open(os.environ['GITHUB_ENV'], 'a') as env_file:
            env_file.write('CATCHSEGV_BINARY=catchsegv\n')
      shell: python

    - name: Run the testing
      # FIXME: Integrate the following once it's possible
      # --installpkg 'dist/${{ needs.pre-setup.outputs.wheel-artifact-name }}'
      run: >-
        python -m
        tox
        --parallel auto
        --parallel-live
        --skip-missing-interpreters false
        -qq
    - name: Produce markdown test summary from JUnit
      if: always()
      uses: test-summary/action@v2.2
      with:
        paths: .test-results/pytest/results.xml
    - name: Re-run the failing tests with maximum verbosity
      if: failure()
      # FIXME: Integrate the following once it's possible
      # --installpkg 'dist/${{ needs.pre-setup.outputs.wheel-artifact-name }}'
      run: >-  # `exit 1` makes sure that the job remains red with flaky runs
        python -m
        tox
        --parallel auto
        --parallel-live
        --skip-missing-interpreters false
        -vvvvv
        --
        --no-cov -vvvvv --lf
        && exit 1
      shell: bash
    - name: Send coverage data to Codecov
      uses: codecov/codecov-action@v3.1.5
      with:
        files: .test-results/pytest/cov.xml
        flags: >-
          CI-GHA,
          OS-${{
            runner.os
          }},
          VM-${{
            inputs.runner-vm-os
          }},
          Py-${{
            steps.python-install.outputs.python-version
          }}

...
